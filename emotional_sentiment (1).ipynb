{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Emotion Classification of Natural Language</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Imports </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, RandomizedSearchCV\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification, AdamW, get_scheduler, TrainingArguments, Trainer\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import multiprocessing\n",
    "import cloudpickle\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Load the Dataset </h5>\n",
    "Due to privacy concerns regarding Cornell University, the training and testing sets are not present. Only the code itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train_text = train[\"text\"]\n",
    "train_label = train[\"label\"]\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_id = test[\"id\"]\n",
    "test_text = test[\"text\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(train['text']).toarray()  \n",
    "y = train['label']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Classical Methods</h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gru split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_text, train_label, test_size=0.2, random_state=123)\n",
    "\n",
    "#Gru Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")  # Adjust num_words as needed\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=100, padding=\"post\", truncating=\"post\")  # Adjust maxlen if needed\n",
    "X_val_padded = pad_sequences(X_val_seq, maxlen=100, padding=\"post\", truncating=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gru Model\n",
    "\n",
    "gru_model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=100),  # Match num_words and maxlen\n",
    "    GRU(128, dropout=0.2, recurrent_dropout=0.2),  # GRU layer\n",
    "    Dense(28, activation=\"softmax\")  # 28 labels for sentiment classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "gru_model.compile(optimizer=Adam(learning_rate=5e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",  # Sparse for integer labels\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gru Train\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "# Train the GRU model\n",
    "history = gru_model.fit(\n",
    "    X_train_padded,\n",
    "    y_train,\n",
    "    validation_data=(X_val_padded, y_val),\n",
    "    epochs=10,  # Adjust epochs as needed\n",
    "    batch_size=32  # Adjust batch size as needed\n",
    ")\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primitive Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into numerical features using Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_text, train_label, test_size=0.2, random_state=123)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model 1\n",
    "log_reg_primitive_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, n_jobs=1, warm_start=True)\n",
    "\n",
    "try:\n",
    "    log_reg_primitive_model.fit(X_train, y_train)\n",
    "    print(\"Model trained successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model fitting: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "param_grid = {\n",
    "    'multi_class': ['ovr', 'multinomial'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'max_iter': [1000, 2000, 5000]\n",
    "}\n",
    "\n",
    "log_reg_model = LogisticRegression()\n",
    "\n",
    "# Set up GridSearchCV to optimize hyperparameters for Logistic Regression\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and cross-validation score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Refined Logistic Regression \n",
    "best_params = grid_search.best_params_\n",
    "log_reg_model = LogisticRegression(**best_params)\n",
    "log_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primitive XGBBoost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "#train XGBoost with default parameters\n",
    "xgb_primitive_model = XGBClassifier()\n",
    "xgb_primitive_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "param_distributions = {\n",
    "    'max_depth': [4, 6, 8],  # Tree depth\n",
    "    'learning_rate': [0.05, 0.1, 0.2],  # Step size\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees\n",
    "    'subsample': [0.8, 1.0],  # Fraction of samples used for training\n",
    "    'colsample_bytree': [0.8, 1.0],  # Fraction of features used per tree\n",
    "}\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=28,\n",
    "    n_jobs=4,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "\n",
    "randomized_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # Test only 50 random combinations\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all available CPU cores\n",
    "    verbose=2  # Show progress\n",
    ")\n",
    "\n",
    "\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters and score\n",
    "print(\"Best Parameters:\", randomized_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", randomized_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "#train XGBoost using optimal parameters\n",
    "#best_params = randomized_search.best_params_ #Extract the best parameters\n",
    "#xgb_model = XGBClassifier(**best_params)\n",
    "xgb_model = XGBClassifier(subsample=1.0, n_estimators=150, max_depth=8, learning_rate=0.2, colsample_bytree=0.8) #Originally gave these outputs which give a higher accuracy score than the new outputs, so not using best_params, but did use code above to get these parameter values\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_text, train_label, test_size=0.2, random_state=123)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "\n",
    "#Evaluate primitive Logistic REgression\n",
    "y_pred = log_reg_primitive_model.predict(X_val)\n",
    "print(\"Primitive Logistic Regression accuracy: \" + str(accuracy_score(y_val, y_pred)))\n",
    "\n",
    "\n",
    "#Evaluate Refined Logistic Regression\n",
    "y_pred = log_reg_model.predict(X_val)\n",
    "print(\"Optimized Logistic Regression accuracy: \" + str(accuracy_score(y_val, y_pred)))\n",
    "\n",
    "\n",
    "#Primitive XGBoost evaluation\n",
    "y_pred = xgb_primitive_model.predict(X_val)\n",
    "print(\"Primitive XGBoost Accuracy: \" + str(accuracy_score(y_val, y_pred)))\n",
    "\n",
    "\n",
    "#Refined XGboost evaluation\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "print(\"Optimized XGBoost Accuracy: \" + str(accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Creative Methods </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea 1: Use a pre-trained BERT in order to get embeddings and then train a logistic regression on these embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
    "model = BertModel.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts, batch_size=32): #adjust batch size as needed \n",
    "    \"\"\"\n",
    "    Generate embeddings using a pretrained BERT model\n",
    "    \"\"\"\n",
    "    device = torch.device('cpu')  # Use CPU\n",
    "    model.to(device)\n",
    "    \n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Use CLS token embeddings\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(train_text, train_label, test_size=0.4, random_state=101)   #split w/ placeholder for the testing & training data\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)   \n",
    "\n",
    "X_train = list(X_train)\n",
    "X_val = list(X_val)\n",
    "X_test = list(X_test)\n",
    "\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating train embeddings...\")\n",
    "X_train_embeddings = generate_embeddings(X_train)\n",
    "\n",
    "print(\"Generating validation embeddings...\")\n",
    "X_val_embeddings = generate_embeddings(X_val)\n",
    "\n",
    "print(\"Generating test embeddings...\")\n",
    "X_test_embeddings = generate_embeddings(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Separate sub-grids for valid configurations\n",
    "param_grid = [\n",
    "    {'multi_class': ['ovr'], 'solver': ['liblinear'], 'C': [0.01, 0.1, 1, 10], 'max_iter': [1000, 2000]},\n",
    "    {'multi_class': ['multinomial'], 'solver': ['lbfgs', 'saga'], 'C': [0.01, 0.1, 1, 10], 'max_iter': [1000, 2000]}\n",
    "]\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logistic_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Get best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "y_val_pred = grid_search.best_estimator_.predict(X_val_embeddings)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy (after tuning): {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = LogisticRegression(C=1, max_iter=1000, multi_class='multinomial', solver='saga') \n",
    "clf.fit(X_train_embeddings, y_train)\n",
    "\n",
    "\n",
    "y_val_pred = clf.predict(X_val_embeddings)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea 2: Take a small-pretrained LLM and finetune it for emotion sentiment classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Class for TextDataset in order to use the Hugging Face Trainer API\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(\n",
    "            texts, truncation=True, padding=True, max_length=128\n",
    "        )\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            key: torch.tensor(val[idx])\n",
    "            for key, val in self.encodings.items()\n",
    "        }\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "val_dataset = TextDataset(X_val, y_val)\n",
    "test_dataset = TextDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Which version of BERT to use\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', num_labels=28\n",
    ")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Training Args for Finetuned BERT \n",
    "training_args = TrainingArguments(\n",
    "    output_dir='.',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    learning_rate=2e-5,\n",
    "    no_cuda=(False if torch.cuda.is_available() else True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model (warning: this script takes ~6hrs to run w/ 4 2.3ghz intel core i9 cores. As such, the model is already trained and saved in the repo)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test BERT Model on partition of train.csv that was saved for evaluation \n",
    "predictions = trainer.predict(test_dataset=test_dataset)\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "\n",
    "predicted_classes = logits.argmax(axis=-1)\n",
    "accuracy = accuracy_score(labels, predicted_classes)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = range(15000)\n",
    "prediction = range(15000)\n",
    "submission = pd.DataFrame({'id': id, 'label': prediction})\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may use pandas to generate a dataframe with country, date and your predictions first \n",
    "# and then use to_csv to generate a CSV file.\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_path = \"checkpoint-4500\" #adjust path as necessary \n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "classification_pipeline = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "predictions = []\n",
    "for text in test_data[\"text\"]:\n",
    "    prediction = classification_pipeline(text)\n",
    "    predicted_label = prediction[0][\"label\"]\n",
    "    predictions.append(predicted_label)\n",
    "\n",
    "\n",
    "test_data[\"label\"] = predictions\n",
    "test_data[\"label\"] = test_data[\"label\"].str.replace(\"LABEL_\", \"\").astype(int)\n",
    "\n",
    "\n",
    "\n",
    "output_file = \"submission.csv\"\n",
    "test_data[[\"id\", \"label\"]].to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
